{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Socket.IO Streaming with LangGraph\n",
    "\n",
    "LangGraphì˜ **ë‹¤ì¤‘ ë…¸ë“œ ê·¸ë˜í”„**ë¥¼ êµ¬ì„±í•˜ê³ , ê° ë‹¨ê³„ë³„ ì´ë²¤íŠ¸ë¥¼ Socket.IOë¡œ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ê·¸ë˜í”„ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "START â†’ [analyzer] â†’ [generator] â†’ [saver] â†’ END\n",
    "           â†“              â†“            â†“\n",
    "        LLM í˜¸ì¶œ       LLM í˜¸ì¶œ     DB ì €ì¥\n",
    "```\n",
    "\n",
    "## ì´ë²¤íŠ¸ íƒ€ì…\n",
    "\n",
    "| ì´ë²¤íŠ¸ | ì„¤ëª… |\n",
    "|--------|------|\n",
    "| `node_start` | ë…¸ë“œ ì‹œì‘ (ë…¸ë“œ ì´ë¦„ í¬í•¨) |\n",
    "| `node_end` | ë…¸ë“œ ì™„ë£Œ (ë…¸ë“œ ì´ë¦„ í¬í•¨) |\n",
    "| `token` | LLM í† í° ìŠ¤íŠ¸ë¦¬ë° |\n",
    "| `db_save` | DB ì €ì¥ ì™„ë£Œ |\n",
    "| `done` | ì „ì²´ ì™„ë£Œ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Annotated, TypedDict, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\n",
    "MODEL_NAME = \"gemma3:12b\"\n",
    "\n",
    "print(f\"Ollama URL: {OLLAMA_URL}\")\n",
    "print(f\"Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=MODEL_NAME,\n",
    "    base_url=OLLAMA_URL,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(f\"{MODEL_NAME} ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mocking DB ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mocking Database\n",
    "class MockDatabase:\n",
    "    \"\"\"ê°„ë‹¨í•œ ì¸ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.records: List[dict] = []\n",
    "    \n",
    "    async def save(self, data: dict) -> dict:\n",
    "        \"\"\"ë°ì´í„° ì €ì¥ (ë¹„ë™ê¸° ì‹œë®¬ë ˆì´ì…˜)\"\"\"\n",
    "        await asyncio.sleep(0.5)  # DB ì €ì¥ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜\n",
    "        \n",
    "        record = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"created_at\": datetime.now().isoformat(),\n",
    "            **data\n",
    "        }\n",
    "        self.records.append(record)\n",
    "        return record\n",
    "    \n",
    "    def get_all(self) -> List[dict]:\n",
    "        return self.records\n",
    "\n",
    "\n",
    "# ì „ì—­ DB ì¸ìŠ¤í„´ìŠ¤\n",
    "mock_db = MockDatabase()\n",
    "print(\"MockDatabase ì´ˆê¸°í™” ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ê·¸ë˜í”„ ìƒíƒœ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"ê·¸ë˜í”„ ìƒíƒœ\"\"\"\n",
    "    # ì›ë³¸ ì…ë ¥\n",
    "    user_input: str\n",
    "    \n",
    "    # ë¶„ì„ ê²°ê³¼\n",
    "    analysis: str\n",
    "    \n",
    "    # ìƒì„±ëœ ì‘ë‹µ\n",
    "    response: str\n",
    "    \n",
    "    # DB ì €ì¥ ê²°ê³¼\n",
    "    saved_record: dict\n",
    "\n",
    "\n",
    "print(\"GraphState ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyzer_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    [Node 1: Analyzer]\n",
    "    ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ ì˜ë„ì™€ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    user_input = state[\"user_input\"]\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¤ìŒ ì‚¬ìš©ì ì…ë ¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.\n",
    "- ì£¼ìš” ì˜ë„\n",
    "- í•µì‹¬ í‚¤ì›Œë“œ\n",
    "- ê°ì • í†¤\n",
    "\n",
    "ì‚¬ìš©ì ì…ë ¥: {user_input}\n",
    "\n",
    "ë¶„ì„ ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ ì‘ì„±í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "    \n",
    "    response = await llm.ainvoke(prompt)\n",
    "    \n",
    "    return {\"analysis\": response.content}\n",
    "\n",
    "\n",
    "async def generator_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    [Node 2: Generator]\n",
    "    ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    user_input = state[\"user_input\"]\n",
    "    analysis = state[\"analysis\"]\n",
    "    \n",
    "    prompt = f\"\"\"ë‹¤ìŒ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì‚¬ìš©ì ì›ë³¸ ì…ë ¥: {user_input}\n",
    "\n",
    "ë¶„ì„ ê²°ê³¼:\n",
    "{analysis}\n",
    "\n",
    "ìœ„ ë¶„ì„ì„ ê³ ë ¤í•˜ì—¬ ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "    \n",
    "    response = await llm.ainvoke(prompt)\n",
    "    \n",
    "    return {\"response\": response.content}\n",
    "\n",
    "\n",
    "async def saver_node(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    [Node 3: Saver]\n",
    "    ëŒ€í™” ë‚´ìš©ì„ DBì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    record = await mock_db.save({\n",
    "        \"user_input\": state[\"user_input\"],\n",
    "        \"analysis\": state[\"analysis\"],\n",
    "        \"response\": state[\"response\"],\n",
    "    })\n",
    "    \n",
    "    return {\"saved_record\": record}\n",
    "\n",
    "\n",
    "print(\"ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ê·¸ë˜í”„ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"analyzer\", analyzer_node)\n",
    "workflow.add_node(\"generator\", generator_node)\n",
    "workflow.add_node(\"saver\", saver_node)\n",
    "\n",
    "# ì—£ì§€ ì •ì˜ (ìˆœì°¨ ì‹¤í–‰)\n",
    "workflow.add_edge(START, \"analyzer\")\n",
    "workflow.add_edge(\"analyzer\", \"generator\")\n",
    "workflow.add_edge(\"generator\", \"saver\")\n",
    "workflow.add_edge(\"saver\", END)\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ì‹œê°í™”\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nê·¸ë˜í”„ êµ¬ì¡°:\")\n",
    "    print(\"START â†’ analyzer â†’ generator â†’ saver â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ê¸°ë³¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë° ì—†ì´)\n",
    "result = await graph.ainvoke({\"user_input\": \"Pythonìœ¼ë¡œ ì›¹ í¬ë¡¤ëŸ¬ë¥¼ ë§Œë“¤ê³  ì‹¶ì–´ìš”\"})\n",
    "\n",
    "print(\"[ê²°ê³¼]\")\n",
    "print(f\"\\nğŸ“Š ë¶„ì„:\\n{result['analysis'][:200]}...\")\n",
    "print(f\"\\nğŸ’¬ ì‘ë‹µ:\\n{result['response'][:200]}...\")\n",
    "print(f\"\\nğŸ’¾ ì €ì¥ëœ ë ˆì½”ë“œ:\\n{result['saved_record']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ì´ë²¤íŠ¸ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ê° ë…¸ë“œì˜ ì‹œì‘/ëê³¼ LLM í† í°ì„ ì´ë²¤íŠ¸ë¡œ ë°›ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def stream_with_events(user_input: str):\n",
    "    \"\"\"\n",
    "    ì´ë²¤íŠ¸ ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° - Socket.IO emit ì‹œë®¬ë ˆì´ì…˜\n",
    "    \"\"\"\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"ì…ë ¥: {user_input}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    current_node = None\n",
    "    \n",
    "    async for event in graph.astream_events(\n",
    "        {\"user_input\": user_input},\n",
    "        version=\"v2\"\n",
    "    ):\n",
    "        kind = event[\"event\"]\n",
    "        \n",
    "        # ë…¸ë“œ ì‹œì‘\n",
    "        if kind == \"on_chain_start\":\n",
    "            node_name = event.get(\"name\", \"\")\n",
    "            if node_name in [\"analyzer\", \"generator\", \"saver\"]:\n",
    "                current_node = node_name\n",
    "                print(f\"\\nğŸš€ [NODE_START] {node_name}\")\n",
    "                # Socket.IO: await sio.emit(\"node_start\", {\"node\": node_name}, to=sid)\n",
    "        \n",
    "        # ë…¸ë“œ ì¢…ë£Œ\n",
    "        elif kind == \"on_chain_end\":\n",
    "            node_name = event.get(\"name\", \"\")\n",
    "            if node_name in [\"analyzer\", \"generator\", \"saver\"]:\n",
    "                print(f\"\\nâœ… [NODE_END] {node_name}\")\n",
    "                # Socket.IO: await sio.emit(\"node_end\", {\"node\": node_name}, to=sid)\n",
    "                \n",
    "                # saver ë…¸ë“œ ì™„ë£Œ ì‹œ DB ì €ì¥ ì´ë²¤íŠ¸\n",
    "                if node_name == \"saver\":\n",
    "                    output = event.get(\"data\", {}).get(\"output\", {})\n",
    "                    if \"saved_record\" in output:\n",
    "                        print(f\"\\nğŸ’¾ [DB_SAVE] {output['saved_record']}\")\n",
    "                        # Socket.IO: await sio.emit(\"db_save\", output[\"saved_record\"], to=sid)\n",
    "        \n",
    "        # LLM í† í° ìŠ¤íŠ¸ë¦¬ë°\n",
    "        elif kind == \"on_chat_model_stream\":\n",
    "            chunk = event.get(\"data\", {}).get(\"chunk\")\n",
    "            if chunk and chunk.content:\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "                # Socket.IO: await sio.emit(\"token\", {\"node\": current_node, \"content\": chunk.content}, to=sid)\n",
    "    \n",
    "    print(f\"\\n\\n{'='*60}\")\n",
    "    print(\"ğŸ‰ [DONE] ì „ì²´ ì™„ë£Œ\")\n",
    "    # Socket.IO: await sio.emit(\"done\", to=sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸\n",
    "await stream_with_events(\"FastAPIë¡œ REST API ì„œë²„ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì €ì¥ëœ ë ˆì½”ë“œ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[ì €ì¥ëœ ëª¨ë“  ë ˆì½”ë“œ]\\n\")\n",
    "for i, record in enumerate(mock_db.get_all(), 1):\n",
    "    print(f\"--- Record {i} ---\")\n",
    "    print(f\"ID: {record['id']}\")\n",
    "    print(f\"ìƒì„±ì¼: {record['created_at']}\")\n",
    "    print(f\"ì…ë ¥: {record['user_input'][:50]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Socket.IO ì„œë²„ ì½”ë“œ (ì‹¤ì œ ì‚¬ìš©)\n",
    "\n",
    "ì•„ë˜ ì½”ë“œë¥¼ ë³„ë„ íŒŒì¼(`streaming_server.py`)ë¡œ ì €ì¥í•˜ì—¬ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_code = '''\n",
    "\"\"\"\n",
    "Deep Socket.IO Streaming Server\n",
    "\n",
    "ì‹¤í–‰: python streaming_server.py\n",
    "í…ŒìŠ¤íŠ¸: http://localhost:8000\n",
    "\"\"\"\n",
    "import os\n",
    "import uuid\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, List\n",
    "\n",
    "import socketio\n",
    "from aiohttp import web\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ============================================================\n",
    "# ì„¤ì •\n",
    "# ============================================================\n",
    "OLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\n",
    "MODEL_NAME = \"gemma3:12b\"\n",
    "\n",
    "# Socket.IO ì„œë²„\n",
    "sio = socketio.AsyncServer(async_mode=\"aiohttp\", cors_allowed_origins=\"*\")\n",
    "app = web.Application()\n",
    "sio.attach(app)\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=MODEL_NAME, base_url=OLLAMA_URL, temperature=0.7)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Mock Database\n",
    "# ============================================================\n",
    "class MockDatabase:\n",
    "    def __init__(self):\n",
    "        self.records: List[dict] = []\n",
    "    \n",
    "    async def save(self, data: dict) -> dict:\n",
    "        await asyncio.sleep(0.3)\n",
    "        record = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"created_at\": datetime.now().isoformat(),\n",
    "            **data\n",
    "        }\n",
    "        self.records.append(record)\n",
    "        return record\n",
    "\n",
    "mock_db = MockDatabase()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Graph State & Nodes\n",
    "# ============================================================\n",
    "class GraphState(TypedDict):\n",
    "    user_input: str\n",
    "    analysis: str\n",
    "    response: str\n",
    "    saved_record: dict\n",
    "\n",
    "\n",
    "async def analyzer_node(state: GraphState) -> GraphState:\n",
    "    prompt = f\"\"\"ë‹¤ìŒ ì…ë ¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš” (ì˜ë„, í‚¤ì›Œë“œ, ê°ì •):\n",
    "{state[\"user_input\"]}\"\"\"\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return {\"analysis\": response.content}\n",
    "\n",
    "\n",
    "async def generator_node(state: GraphState) -> GraphState:\n",
    "    prompt = f\"\"\"ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
    "ì…ë ¥: {state[\"user_input\"]}\n",
    "ë¶„ì„: {state[\"analysis\"]}\"\"\"\n",
    "    response = await llm.ainvoke(prompt)\n",
    "    return {\"response\": response.content}\n",
    "\n",
    "\n",
    "async def saver_node(state: GraphState) -> GraphState:\n",
    "    record = await mock_db.save({\n",
    "        \"user_input\": state[\"user_input\"],\n",
    "        \"analysis\": state[\"analysis\"],\n",
    "        \"response\": state[\"response\"],\n",
    "    })\n",
    "    return {\"saved_record\": record}\n",
    "\n",
    "\n",
    "# ê·¸ë˜í”„ ë¹Œë“œ\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"analyzer\", analyzer_node)\n",
    "workflow.add_node(\"generator\", generator_node)\n",
    "workflow.add_node(\"saver\", saver_node)\n",
    "workflow.add_edge(START, \"analyzer\")\n",
    "workflow.add_edge(\"analyzer\", \"generator\")\n",
    "workflow.add_edge(\"generator\", \"saver\")\n",
    "workflow.add_edge(\"saver\", END)\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Socket.IO Events\n",
    "# ============================================================\n",
    "@sio.event\n",
    "async def connect(sid, environ):\n",
    "    print(f\"[ì—°ê²°] {sid}\")\n",
    "    await sio.emit(\"connected\", {\"sid\": sid}, to=sid)\n",
    "\n",
    "\n",
    "@sio.event\n",
    "async def disconnect(sid):\n",
    "    print(f\"[ì—°ê²° í•´ì œ] {sid}\")\n",
    "\n",
    "\n",
    "@sio.event\n",
    "async def chat(sid, data):\n",
    "    \"\"\"ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ - ì „ì²´ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë°\"\"\"\n",
    "    user_input = data.get(\"message\", \"\")\n",
    "    print(f\"[{sid}] ì…ë ¥: {user_input}\")\n",
    "    \n",
    "    current_node = None\n",
    "    \n",
    "    try:\n",
    "        async for event in graph.astream_events(\n",
    "            {\"user_input\": user_input},\n",
    "            version=\"v2\"\n",
    "        ):\n",
    "            kind = event[\"event\"]\n",
    "            \n",
    "            # ë…¸ë“œ ì‹œì‘\n",
    "            if kind == \"on_chain_start\":\n",
    "                node_name = event.get(\"name\", \"\")\n",
    "                if node_name in [\"analyzer\", \"generator\", \"saver\"]:\n",
    "                    current_node = node_name\n",
    "                    await sio.emit(\"node_start\", {\"node\": node_name}, to=sid)\n",
    "            \n",
    "            # ë…¸ë“œ ì¢…ë£Œ\n",
    "            elif kind == \"on_chain_end\":\n",
    "                node_name = event.get(\"name\", \"\")\n",
    "                if node_name in [\"analyzer\", \"generator\", \"saver\"]:\n",
    "                    output = event.get(\"data\", {}).get(\"output\", {})\n",
    "                    await sio.emit(\"node_end\", {\n",
    "                        \"node\": node_name,\n",
    "                        \"output\": str(output)[:500]  # ì¶œë ¥ ì¼ë¶€ë§Œ\n",
    "                    }, to=sid)\n",
    "                    \n",
    "                    # DB ì €ì¥ ì´ë²¤íŠ¸\n",
    "                    if node_name == \"saver\" and \"saved_record\" in output:\n",
    "                        await sio.emit(\"db_save\", output[\"saved_record\"], to=sid)\n",
    "            \n",
    "            # LLM í† í° ìŠ¤íŠ¸ë¦¬ë°\n",
    "            elif kind == \"on_chat_model_stream\":\n",
    "                chunk = event.get(\"data\", {}).get(\"chunk\")\n",
    "                if chunk and chunk.content:\n",
    "                    await sio.emit(\"token\", {\n",
    "                        \"node\": current_node,\n",
    "                        \"content\": chunk.content\n",
    "                    }, to=sid)\n",
    "        \n",
    "        # ì™„ë£Œ\n",
    "        await sio.emit(\"done\", {\"success\": True}, to=sid)\n",
    "    \n",
    "    except Exception as e:\n",
    "        await sio.emit(\"error\", {\"message\": str(e)}, to=sid)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# HTML í…ŒìŠ¤íŠ¸ í˜ì´ì§€\n",
    "# ============================================================\n",
    "HTML_PAGE = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Deep Streaming Test</title>\n",
    "    <script src=\"https://cdn.socket.io/4.7.2/socket.io.min.js\"></script>\n",
    "    <style>\n",
    "        body { font-family: monospace; padding: 20px; background: #1a1a2e; color: #eee; }\n",
    "        #output { background: #16213e; padding: 20px; border-radius: 8px; height: 400px; overflow-y: auto; }\n",
    "        .node-start { color: #00ff88; }\n",
    "        .node-end { color: #00ccff; }\n",
    "        .token { color: #fff; }\n",
    "        .db-save { color: #ffcc00; }\n",
    "        .done { color: #ff88ff; font-weight: bold; }\n",
    "        .error { color: #ff4444; }\n",
    "        input { width: 70%; padding: 10px; font-size: 16px; }\n",
    "        button { padding: 10px 20px; font-size: 16px; cursor: pointer; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>ğŸš€ Deep Socket.IO Streaming</h1>\n",
    "    <input type=\"text\" id=\"input\" placeholder=\"ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...\" />\n",
    "    <button onclick=\"sendMessage()\">ì „ì†¡</button>\n",
    "    <div id=\"output\"></div>\n",
    "    \n",
    "    <script>\n",
    "        const socket = io();\n",
    "        const output = document.getElementById('output');\n",
    "        \n",
    "        function log(msg, cls = '') {\n",
    "            output.innerHTML += `<div class=\"${cls}\">${msg}</div>`;\n",
    "            output.scrollTop = output.scrollHeight;\n",
    "        }\n",
    "        \n",
    "        socket.on('connected', (data) => log(`âœ… ì—°ê²°ë¨: ${data.sid}`));\n",
    "        \n",
    "        socket.on('node_start', (data) => {\n",
    "            log(`<br>ğŸš€ [NODE START] ${data.node}`, 'node-start');\n",
    "        });\n",
    "        \n",
    "        socket.on('node_end', (data) => {\n",
    "            log(`<br>âœ… [NODE END] ${data.node}`, 'node-end');\n",
    "        });\n",
    "        \n",
    "        socket.on('token', (data) => {\n",
    "            // í† í°ì€ ì¤„ë°”ê¿ˆ ì—†ì´ ì´ì–´ë¶™ì„\n",
    "            const lastDiv = output.lastElementChild;\n",
    "            if (lastDiv && lastDiv.classList.contains('token')) {\n",
    "                lastDiv.innerHTML += data.content;\n",
    "            } else {\n",
    "                log(data.content, 'token');\n",
    "            }\n",
    "            output.scrollTop = output.scrollHeight;\n",
    "        });\n",
    "        \n",
    "        socket.on('db_save', (data) => {\n",
    "            log(`<br>ğŸ’¾ [DB SAVE] ID: ${data.id}`, 'db-save');\n",
    "        });\n",
    "        \n",
    "        socket.on('done', () => {\n",
    "            log(`<br>ğŸ‰ [DONE] ì™„ë£Œ!`, 'done');\n",
    "        });\n",
    "        \n",
    "        socket.on('error', (data) => {\n",
    "            log(`<br>âŒ [ERROR] ${data.message}`, 'error');\n",
    "        });\n",
    "        \n",
    "        function sendMessage() {\n",
    "            const input = document.getElementById('input');\n",
    "            const message = input.value.trim();\n",
    "            if (message) {\n",
    "                log(`<br>ğŸ“¤ [SEND] ${message}`, 'node-start');\n",
    "                socket.emit('chat', { message });\n",
    "                input.value = '';\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        document.getElementById('input').addEventListener('keypress', (e) => {\n",
    "            if (e.key === 'Enter') sendMessage();\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "async def index(request):\n",
    "    return web.Response(text=HTML_PAGE, content_type=\"text/html\")\n",
    "\n",
    "app.router.add_get(\"/\", index)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ì„œë²„ ì‹¤í–‰\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Ollama URL: {OLLAMA_URL}\")\n",
    "    print(f\"Model: {MODEL_NAME}\")\n",
    "    print(\"\\nğŸš€ ì„œë²„ ì‹œì‘: http://localhost:8000\")\n",
    "    web.run_app(app, host=\"0.0.0.0\", port=8000)\n",
    "'''\n",
    "\n",
    "# íŒŒì¼ë¡œ ì €ì¥\n",
    "server_file_path = \"streaming_server.py\"\n",
    "with open(server_file_path, \"w\") as f:\n",
    "    f.write(server_code)\n",
    "\n",
    "print(f\"âœ… ì„œë²„ ì½”ë“œê°€ '{server_file_path}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "print(\"\\nì‹¤í–‰ ë°©ë²•:\")\n",
    "print(f\"  python {server_file_path}\")\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸:\")\n",
    "print(\"  http://localhost:8000 ì ‘ì†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ì´ë²¤íŠ¸ íë¦„ ìš”ì•½\n",
    "\n",
    "```\n",
    "í´ë¼ì´ì–¸íŠ¸                     ì„œë²„                          LangGraph\n",
    "    â”‚                           â”‚                               â”‚\n",
    "    â”‚â”€â”€â”€â”€ chat {message} â”€â”€â”€â”€â”€â”€>â”‚                               â”‚\n",
    "    â”‚                           â”‚â”€â”€â”€â”€ astream_events() â”€â”€â”€â”€â”€â”€â”€â”€>â”‚\n",
    "    â”‚                           â”‚                               â”‚\n",
    "    â”‚<â”€â”€ node_start: analyzer â”€â”€â”‚<â”€â”€ on_chain_start: analyzer â”€â”€â”‚\n",
    "    â”‚<â”€â”€ token â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚<â”€â”€ on_chat_model_stream â”€â”€â”€â”€â”€â”€â”‚\n",
    "    â”‚<â”€â”€ token â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚<â”€â”€ on_chat_model_stream â”€â”€â”€â”€â”€â”€â”‚\n",
    "    â”‚<â”€â”€ node_end: analyzer â”€â”€â”€â”€â”‚<â”€â”€ on_chain_end: analyzer â”€â”€â”€â”€â”‚\n",
    "    â”‚                           â”‚                               â”‚\n",
    "    â”‚<â”€â”€ node_start: generator â”€â”‚<â”€â”€ on_chain_start: generator â”€â”‚\n",
    "    â”‚<â”€â”€ token â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚<â”€â”€ on_chat_model_stream â”€â”€â”€â”€â”€â”€â”‚\n",
    "    â”‚<â”€â”€ token â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚<â”€â”€ on_chat_model_stream â”€â”€â”€â”€â”€â”€â”‚\n",
    "    â”‚<â”€â”€ node_end: generator â”€â”€â”€â”‚<â”€â”€ on_chain_end: generator â”€â”€â”€â”‚\n",
    "    â”‚                           â”‚                               â”‚\n",
    "    â”‚<â”€â”€ node_start: saver â”€â”€â”€â”€â”€â”‚<â”€â”€ on_chain_start: saver â”€â”€â”€â”€â”€â”‚\n",
    "    â”‚<â”€â”€ node_end: saver â”€â”€â”€â”€â”€â”€â”€â”‚<â”€â”€ on_chain_end: saver â”€â”€â”€â”€â”€â”€â”€â”‚\n",
    "    â”‚<â”€â”€ db_save {record} â”€â”€â”€â”€â”€â”€â”‚                               â”‚\n",
    "    â”‚                           â”‚                               â”‚\n",
    "    â”‚<â”€â”€ done â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                               â”‚\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ìš”ì•½\n",
    "\n",
    "### Socket.IO ì´ë²¤íŠ¸\n",
    "\n",
    "| ì´ë²¤íŠ¸ | ë°©í–¥ | ë°ì´í„° |\n",
    "|--------|------|--------|\n",
    "| `chat` | Client â†’ Server | `{message: string}` |\n",
    "| `node_start` | Server â†’ Client | `{node: string}` |\n",
    "| `node_end` | Server â†’ Client | `{node: string, output: string}` |\n",
    "| `token` | Server â†’ Client | `{node: string, content: string}` |\n",
    "| `db_save` | Server â†’ Client | `{id, created_at, ...}` |\n",
    "| `done` | Server â†’ Client | `{success: boolean}` |\n",
    "| `error` | Server â†’ Client | `{message: string}` |\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ\n",
    "\n",
    "```python\n",
    "async for event in graph.astream_events(input, version=\"v2\"):\n",
    "    kind = event[\"event\"]\n",
    "    \n",
    "    if kind == \"on_chain_start\" and event[\"name\"] in NODES:\n",
    "        await sio.emit(\"node_start\", {\"node\": event[\"name\"]}, to=sid)\n",
    "    \n",
    "    elif kind == \"on_chat_model_stream\":\n",
    "        await sio.emit(\"token\", {\"content\": chunk.content}, to=sid)\n",
    "    \n",
    "    elif kind == \"on_chain_end\" and event[\"name\"] in NODES:\n",
    "        await sio.emit(\"node_end\", {\"node\": event[\"name\"]}, to=sid)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
