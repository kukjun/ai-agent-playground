{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# 메모리를 가진 계층적 에이전트 챗봇\n",
    "\n",
    "이 예제에서는 **Checkpointer**를 사용하여 대화 상태를 유지하는 챗봇을 구현합니다.\n",
    "\n",
    "## 구조\n",
    "- **Supervisor**: 사용자 요청을 분석하여 적절한 팀에 라우팅\n",
    "- **Research Team**: 웹 검색 및 정보 수집\n",
    "- **Writing Team**: 문서 작성 및 편집\n",
    "- **Checkpointer**: 대화 히스토리 유지 (thread_id별)\n",
    "\n",
    "## 일반 그래프 vs 메모리 그래프\n",
    "\n",
    "| 구분 | 일반 그래프 | 메모리 그래프 |\n",
    "|------|------------|---------------|\n",
    "| 상태 유지 | 호출 끝나면 휘발 | thread_id별 영구 유지 |\n",
    "| 대화 연속성 | 매번 새로 시작 | 이전 대화 기억 |\n",
    "| 용도 | 단발성 작업 | 챗봇, 멀티턴 대화 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\n",
    "MODEL_NAME = \"gpt-oss:20b\"\n",
    "\n",
    "print(f\"Ollama URL: {OLLAMA_URL}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "\n",
    "if os.getenv(\"LANGCHAIN_API_KEY\"):\n",
    "    print(f\"LangSmith: 활성화 ({os.getenv('LANGCHAIN_PROJECT', 'default')})\")\n",
    "else:\n",
    "    print(\"LangSmith: 비활성화\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-header",
   "metadata": {},
   "source": [
    "## 2. LLM 및 도구 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llm-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=MODEL_NAME,\n",
    "    base_url=OLLAMA_URL,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 간단한 시뮬레이션 도구들 (실제 API 대신)\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"웹에서 정보를 검색합니다.\"\"\"\n",
    "    # 시뮬레이션된 검색 결과\n",
    "    results = {\n",
    "        \"ai\": \"AI(인공지능)는 기계가 인간의 지능을 모방하는 기술입니다. 머신러닝, 딥러닝, 자연어처리 등이 포함됩니다.\",\n",
    "        \"python\": \"Python은 1991년 귀도 반 로섬이 만든 프로그래밍 언어입니다. 간결한 문법과 풍부한 라이브러리가 특징입니다.\",\n",
    "        \"langgraph\": \"LangGraph는 LangChain 팀이 만든 라이브러리로, 상태 기반 멀티에이전트 워크플로우를 구축할 수 있습니다.\",\n",
    "    }\n",
    "    for key, value in results.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    return f\"'{query}'에 대한 검색 결과: 일반적인 정보를 찾았습니다.\"\n",
    "\n",
    "@tool\n",
    "def write_document(title: str, content: str) -> str:\n",
    "    \"\"\"문서를 작성합니다.\"\"\"\n",
    "    return f\"문서 '{title}'이(가) 작성되었습니다.\\n\\n내용:\\n{content}\"\n",
    "\n",
    "@tool\n",
    "def summarize_text(text: str) -> str:\n",
    "    \"\"\"텍스트를 요약합니다.\"\"\"\n",
    "    # 간단한 시뮬레이션\n",
    "    if len(text) > 100:\n",
    "        return text[:100] + \"... (요약됨)\"\n",
    "    return text\n",
    "\n",
    "print(\"도구 정의 완료:\", [search_web.name, write_document.name, summarize_text.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "state-header",
   "metadata": {},
   "source": [
    "## 3. 상태 및 Supervisor 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "state-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    \"\"\"대화 상태 - messages는 Checkpointer에 의해 유지됨\"\"\"\n",
    "    next: str\n",
    "\n",
    "\n",
    "def make_supervisor_node(llm, members: list[str]):\n",
    "    \"\"\"Supervisor 노드 생성\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    system_prompt = (\n",
    "        \"You are a supervisor tasked with managing a conversation between the\"\n",
    "        f\" following workers: {members}. Given the following user request,\"\n",
    "        \" respond with the worker to act next. Each worker will perform a\"\n",
    "        \" task and respond with their results and status. When finished,\"\n",
    "        \" respond with FINISH.\"\n",
    "        f\"\\n\\nYou must respond with ONLY one of these options: {options}\"\n",
    "    )\n",
    "\n",
    "    class Router(BaseModel):\n",
    "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "        next: str = Field(description=f\"Next worker to route to. Must be one of: {options}\")\n",
    "\n",
    "    def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "        \"\"\"LLM 기반 라우터.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + state[\"messages\"]\n",
    "        \n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response.next\n",
    "        if goto == \"FINISH\":\n",
    "            goto = END\n",
    "\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "    return supervisor_node\n",
    "\n",
    "print(\"Supervisor 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "teams-header",
   "metadata": {},
   "source": [
    "## 4. 팀 에이전트 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "teams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research Team\n",
    "research_agent = create_react_agent(\n",
    "    llm, \n",
    "    tools=[search_web],\n",
    "    prompt=\"당신은 정보를 검색하고 조사하는 리서치 전문가입니다. 사용자의 질문에 대해 검색하고 답변하세요.\"\n",
    ")\n",
    "\n",
    "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = research_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"research_team\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Writing Team\n",
    "writing_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[write_document, summarize_text],\n",
    "    prompt=\"당신은 문서 작성 전문가입니다. 요청에 따라 문서를 작성하거나 텍스트를 요약하세요.\"\n",
    ")\n",
    "\n",
    "def writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = writing_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"writing_team\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "print(\"팀 에이전트 정의 완료 (HumanMessage 사용)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-header",
   "metadata": {},
   "source": [
    "## 5. 그래프 구성 (with Checkpointer)\n",
    "\n",
    "**핵심**: `MemorySaver`를 사용하여 대화 상태를 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Checkpointer 생성 - 메모리에 상태 저장\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Supervisor 노드 생성\n",
    "supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"research_team\", research_node)\n",
    "builder.add_node(\"writing_team\", writing_node)\n",
    "\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Checkpointer와 함께 컴파일 - 이것이 핵심!\n",
    "chatbot = builder.compile(checkpointer=memory)\n",
    "\n",
    "print(\"챗봇 그래프 컴파일 완료 (with MemorySaver)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(chatbot.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chat-header",
   "metadata": {},
   "source": [
    "## 6. 챗봇 대화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chat-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message: str, thread_id: str = \"default\"):\n",
    "    \"\"\"\n",
    "    챗봇과 대화합니다.\n",
    "    \n",
    "    Args:\n",
    "        message: 사용자 메시지\n",
    "        thread_id: 대화 스레드 ID (같은 ID면 대화 이어짐)\n",
    "    \"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"[사용자] {message}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 스트리밍으로 실행\n",
    "    for event in chatbot.stream(\n",
    "        {\"messages\": [(\"user\", message)]},\n",
    "        config,\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        for node_name, node_output in event.items():\n",
    "            if node_name == \"supervisor\":\n",
    "                next_node = node_output.get(\"next\", \"unknown\")\n",
    "                print(f\"\\n[Supervisor] → {next_node}\")\n",
    "            elif \"messages\" in node_output:\n",
    "                for msg in node_output[\"messages\"]:\n",
    "                    if hasattr(msg, \"content\") and msg.content:\n",
    "                        print(f\"\\n[{node_name}]\")\n",
    "                        print(msg.content[:500] + \"...\" if len(msg.content) > 500 else msg.content)\n",
    "\n",
    "\n",
    "def show_history(thread_id: str = \"default\"):\n",
    "    \"\"\"대화 히스토리를 확인합니다.\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    state = chatbot.get_state(config)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Thread '{thread_id}' 대화 히스토리\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if state.values:\n",
    "        messages = state.values.get(\"messages\", [])\n",
    "        for i, msg in enumerate(messages):\n",
    "            role = msg.type if hasattr(msg, 'type') else 'unknown'\n",
    "            name = getattr(msg, 'name', '')\n",
    "            content = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
    "            print(f\"\\n[{i+1}] {role} {f'({name})' if name else ''}\")\n",
    "            print(f\"    {content}\")\n",
    "    else:\n",
    "        print(\"대화 히스토리가 없습니다.\")\n",
    "\n",
    "print(\"대화 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-header",
   "metadata": {},
   "source": [
    "## 7. 테스트: 대화 연속성 확인\n",
    "\n",
    "같은 `thread_id`로 여러 번 호출하면 이전 대화를 기억합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 대화 - AI에 대해 질문\n",
    "chat(\"AI가 뭐야?\", thread_id=\"user-123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 대화 - 이전 대화를 참조하는 후속 질문\n",
    "chat(\"방금 설명한 내용을 문서로 정리해줘\", thread_id=\"user-123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 번째 대화 - 또 다른 후속 질문\n",
    "chat(\"더 자세히 알려줘\", thread_id=\"user-123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "show-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 히스토리 확인\n",
    "show_history(thread_id=\"user-123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## 8. 비교: 다른 thread_id는 별도 대화\n",
    "\n",
    "다른 `thread_id`를 사용하면 새로운 대화가 시작됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 사용자의 대화 (새로운 thread)\n",
    "chat(\"Python이 뭐야?\", thread_id=\"user-456\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-456의 히스토리 - user-123과 별도\n",
    "show_history(thread_id=\"user-456\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-123의 히스토리 - 여전히 유지됨\n",
    "show_history(thread_id=\"user-123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 9. 요약\n",
    "\n",
    "### Checkpointer의 역할\n",
    "\n",
    "```python\n",
    "# 핵심 코드\n",
    "memory = MemorySaver()\n",
    "chatbot = builder.compile(checkpointer=memory)\n",
    "\n",
    "# 호출 시 thread_id로 대화 구분\n",
    "config = {\"configurable\": {\"thread_id\": \"user-123\"}}\n",
    "chatbot.invoke({\"messages\": [...]}, config)\n",
    "```\n",
    "\n",
    "### 상태 유지 구조\n",
    "\n",
    "```\n",
    "MemorySaver\n",
    "├── thread: \"user-123\"\n",
    "│   └── State\n",
    "│       ├── messages: [User, AI, User, AI, ...] (누적)\n",
    "│       └── next: \"research_team\"\n",
    "│\n",
    "├── thread: \"user-456\"\n",
    "│   └── State\n",
    "│       ├── messages: [...] (별도 대화)\n",
    "│       └── next: \"...\"\n",
    "│\n",
    "└── thread: \"user-789\"\n",
    "    └── ...\n",
    "```\n",
    "\n",
    "### 프로덕션 환경\n",
    "\n",
    "| 환경 | Checkpointer | 특징 |\n",
    "|------|--------------|------|\n",
    "| 개발/테스트 | `MemorySaver` | 메모리, 재시작 시 휘발 |\n",
    "| 프로덕션 | `SqliteSaver` | 파일 기반, 영구 저장 |\n",
    "| 대규모 | `PostgresSaver` | DB 기반, 확장성 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
