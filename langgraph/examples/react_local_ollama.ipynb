{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct Pattern with Local Ollama Model\n",
    "\n",
    "ReAct (Reasoning + Acting) 패턴을 **로컬 Ollama 모델**을 사용하여 구현합니다.\n",
    "\n",
    "## 사전 요구사항\n",
    "1. [Ollama](https://ollama.ai/) 설치\n",
    "2. 모델 다운로드: `ollama pull gemma3:4b`\n",
    "3. Ollama 서버 실행 중 (기본: http://localhost:11434)\n",
    "\n",
    "## 지원 모델 (도구 호출 지원)\n",
    "- `gemma3:4b` (추천 - 경량, 빠름)\n",
    "- `llama3.1`\n",
    "- `llama3.2`\n",
    "- `mistral`\n",
    "- `qwen2.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom dotenv import load_dotenv\n\n# .env 파일에서 환경변수 로드\nload_dotenv()\n\n# Ollama URL 설정 (기본값: localhost:11434)\nOLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\nprint(f\"Ollama URL: {OLLAMA_URL}\")\n\n# LangSmith 트레이싱 설정 확인\nif os.getenv(\"LANGCHAIN_API_KEY\"):\n    print(f\"LangSmith 트레이싱: 활성화\")\n    print(f\"프로젝트: {os.getenv('LANGCHAIN_PROJECT', 'default')}\")\nelse:\n    print(\"LangSmith 트레이싱: 비활성화 (LANGCHAIN_API_KEY 없음)\")"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama 서버 연결 성공!\n",
      "사용 가능한 모델: ['qwen3:8b', 'candiy:4b', 'candiy:12b', 'bge-m3:latest', 'sakak:8b', 'nomic-embed-text:latest', 'gemma3:12b', 'gemma3:4b', 'gemma3:1b', 'candiy:8b', 'candiy-insurance:8b', 'candiy:2b', 'aya:8b', 'llama3.2:1b', 'gemma2:2b']\n"
     ]
    }
   ],
   "source": [
    "# Ollama 서버 연결 확인\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{OLLAMA_URL}/api/tags\")\n",
    "    if response.status_code == 200:\n",
    "        models = response.json().get(\"models\", [])\n",
    "        print(\"Ollama 서버 연결 성공!\")\n",
    "        print(f\"사용 가능한 모델: {[m['name'] for m in models]}\")\n",
    "    else:\n",
    "        print(f\"Ollama 서버 응답 오류: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Ollama 서버에 연결할 수 없습니다.\")\n",
    "    print(\"Ollama가 실행 중인지 확인해주세요: ollama serve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 도구(Tools) 정의\n",
    "\n",
    "ReAct 에이전트가 사용할 도구들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정의된 도구: ['add', 'multiply', 'divide', 'get_weather']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide the first number by the second number.\"\"\"\n",
    "    if b == 0:\n",
    "        return \"Error: Cannot divide by zero.\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city. (Simulation)\"\"\"\n",
    "    weather_data = {\n",
    "        \"seoul\": \"Sunny, 15°C\",\n",
    "        \"busan\": \"Cloudy, 18°C\",\n",
    "        \"jeju\": \"Rainy, 20°C\",\n",
    "        \"daejeon\": \"Sunny, 16°C\",\n",
    "        \"new york\": \"Cloudy, 10°C\",\n",
    "        \"tokyo\": \"Sunny, 22°C\",\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f\"Weather data not found for {city}.\")\n",
    "\n",
    "\n",
    "# 사용할 도구 목록\n",
    "tools = [add, multiply, divide, get_weather]\n",
    "print(f\"정의된 도구: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LLM 설정 (Local Ollama)\n",
    "\n",
    "도구 호출을 지원하는 로컬 모델을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-oss:20b 모델 설정 완료!\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# 사용할 모델 선택 (도구 호출 지원 모델)\n",
    "MODEL_NAME = \"qwen3:8b\"  # 또는 \"llama3.1\", \"mistral\", \"qwen2.5\" 등\n",
    "\n",
    "# Ollama 모델 초기화\n",
    "llm = ChatOllama(\n",
    "    model=MODEL_NAME,\n",
    "    base_url=OLLAMA_URL,\n",
    "    temperature=0,  # 일관된 출력을 위해 0으로 설정\n",
    ")\n",
    "\n",
    "# 도구를 바인딩한 LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(f\"{MODEL_NAME} 모델 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LangGraph를 사용한 ReAct 에이전트 구현\n",
    "\n",
    "### 4.1 방법 1: `create_react_agent` 사용 (간단한 방법)\n",
    "\n",
    "> **Note**: LangGraph v1.0에서 deprecated 경고가 나오지만 정상 작동합니다. v2.0에서 제거될 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReAct 에이전트 생성 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/86/k845p81j4rxdqvdz378b78ym0000gn/T/ipykernel_91158/3015505801.py:4: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  react_agent = create_react_agent(llm, tools)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# ReAct 에이전트 생성 (deprecated 경고가 나오지만 정상 작동)\n",
    "react_agent = create_react_agent(llm, tools)\n",
    "\n",
    "print(\"ReAct 에이전트 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[human]: Add 3 and 5, then multiply the result by 2\n",
      "[ai]: \n",
      "  -> Tool calls: [{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': '75c4943c-c980-427f-ae38-f202746eb8c4', 'type': 'tool_call'}]\n",
      "[tool]: 8\n",
      "[ai]: \n",
      "  -> Tool calls: [{'name': 'multiply', 'args': {'a': 8, 'b': 2}, 'id': '8897dae5-7c3e-42b6-a3f3-1855833541da', 'type': 'tool_call'}]\n",
      "[tool]: 16\n",
      "[ai]: The result is **16**.\n"
     ]
    }
   ],
   "source": [
    "# 간단한 테스트 (영어 사용 권장 - 로컬 모델은 영어 성능이 더 좋음)\n",
    "response = react_agent.invoke({\"messages\": [(\"human\", \"Add 3 and 5, then multiply the result by 2\")]})\n",
    "\n",
    "# 결과 출력\n",
    "for message in response[\"messages\"]:\n",
    "    print(f\"[{message.type}]: {message.content}\")\n",
    "    if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "        print(f\"  -> Tool calls: {message.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 방법 2: 수동으로 ReAct 그래프 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수동 ReAct 그래프 구성 완료!\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "# 상태 정의\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "# 에이전트 노드\n",
    "def agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"에이전트가 추론하고 다음 행동을 결정합니다.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 조건부 라우팅\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"도구를 호출해야 하는지 결정합니다.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "# 도구 노드\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# 그래프 구성\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "custom_react_agent = workflow.compile()\n",
    "\n",
    "print(\"수동 ReAct 그래프 구성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 시각화\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(custom_react_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"그래프 시각화 실패: {e}\")\n",
    "    print(\"그래프 구조: START -> agent -> (tools -> agent) | END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 테스트 케이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(query: str, agent=react_agent, verbose: bool = True):\n",
    "    \"\"\"에이전트를 실행하고 결과를 출력합니다.\"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    response = agent.invoke({\"messages\": [(\"human\", query)]})\n",
    "    \n",
    "    if verbose:\n",
    "        for msg in response[\"messages\"]:\n",
    "            if msg.type == \"human\":\n",
    "                continue\n",
    "            elif msg.type == \"ai\":\n",
    "                if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "                    print(f\"\\n[AI - Tool Calls]\")\n",
    "                    for tc in msg.tool_calls:\n",
    "                        print(f\"  -> {tc['name']}({tc['args']})\")\n",
    "                elif msg.content:\n",
    "                    print(f\"\\n[AI - Final Response]\")\n",
    "                    print(f\"  {msg.content}\")\n",
    "            elif msg.type == \"tool\":\n",
    "                print(f\"\\n[Tool Result] {msg.name}: {msg.content}\")\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: Add 10 and 20, then divide the result by 3\n",
      "============================================================\n",
      "\n",
      "[AI - Tool Calls]\n",
      "  -> add({'a': 10, 'b': 20})\n",
      "\n",
      "[Tool Result] add: 30\n",
      "\n",
      "[AI - Tool Calls]\n",
      "  -> divide({'a': 30, 'b': 3})\n",
      "\n",
      "[Tool Result] divide: 10.0\n",
      "\n",
      "[AI - Final Response]\n",
      "  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Add 10 and 20, then divide the result by 3', additional_kwargs={}, response_metadata={}, id='d20c62b4-cf80-4bb1-b355-c206e41ce578'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-12-03T01:19:41.927438027Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6367322267, 'load_duration': 5608000188, 'prompt_eval_count': 218, 'prompt_eval_duration': 69952066, 'eval_count': 79, 'eval_duration': 603294818, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--245d3f64-cf76-40c4-a134-a7321060f36a-0', tool_calls=[{'name': 'add', 'args': {'a': 10, 'b': 20}, 'id': 'bc92b47b-ef96-4704-8c3d-f31c5ef29b7b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 218, 'output_tokens': 79, 'total_tokens': 297}),\n",
       "  ToolMessage(content='30', name='add', id='fc823b2f-9673-4337-a910-8ae948618c76', tool_call_id='bc92b47b-ef96-4704-8c3d-f31c5ef29b7b'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-12-03T01:19:42.667153308Z', 'done': True, 'done_reason': 'stop', 'total_duration': 639080497, 'load_duration': 149038914, 'prompt_eval_count': 250, 'prompt_eval_duration': 28160004, 'eval_count': 51, 'eval_duration': 386029359, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--af797e1a-a431-4e81-9bec-7c0a623bb03d-0', tool_calls=[{'name': 'divide', 'args': {'a': 30, 'b': 3}, 'id': 'afae77ca-67e4-4811-9e3d-385ea29efea5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 250, 'output_tokens': 51, 'total_tokens': 301}),\n",
       "  ToolMessage(content='10.0', name='divide', id='31ca4c1d-9f9b-4943-81c2-877b4fea75da', tool_call_id='afae77ca-67e4-4811-9e3d-385ea29efea5'),\n",
       "  AIMessage(content='10', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-12-03T01:19:43.452247941Z', 'done': True, 'done_reason': 'stop', 'total_duration': 764384706, 'load_duration': 150911806, 'prompt_eval_count': 284, 'prompt_eval_duration': 31229190, 'eval_count': 69, 'eval_duration': 524929674, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--7f880507-5cc2-4da0-b879-f8a005c818fd-0', usage_metadata={'input_tokens': 284, 'output_tokens': 69, 'total_tokens': 353})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 1: 수학 연산 (영어)\n",
    "run_agent(\"Add 10 and 20, then divide the result by 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: What is the weather in Seoul and Tokyo?\n",
      "============================================================\n",
      "\n",
      "[AI - Tool Calls]\n",
      "  -> get_weather({'city': 'Seoul'})\n",
      "\n",
      "[Tool Result] get_weather: Sunny, 15°C\n",
      "\n",
      "[AI - Tool Calls]\n",
      "  -> get_weather({'city': 'Tokyo'})\n",
      "\n",
      "[Tool Result] get_weather: Sunny, 22°C\n",
      "\n",
      "[AI - Final Response]\n",
      "  Here’s the current weather for each city:\n",
      "\n",
      "| City | Weather | Temperature |\n",
      "|------|---------|-------------|\n",
      "| Seoul | Sunny | 15 °C |\n",
      "| Tokyo | Sunny | 22 °C |\n",
      "\n",
      "Let me know if you’d like more details (e.g., humidity, wind speed, forecast for the next few days, or anything else)!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in Seoul and Tokyo?', additional_kwargs={}, response_metadata={}, id='fa3c3b1f-b38c-41c9-922c-3c735cb13449'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-12-03T01:19:44.255225178Z', 'done': True, 'done_reason': 'stop', 'total_duration': 770919393, 'load_duration': 141306053, 'prompt_eval_count': 213, 'prompt_eval_duration': 124520424, 'eval_count': 63, 'eval_duration': 476482509, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--d27ce87c-dbd5-459e-a469-99bed8f87667-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Seoul'}, 'id': '3354c9f2-0bcc-4344-8168-37c67d37c5c0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 213, 'output_tokens': 63, 'total_tokens': 276}),\n",
       "  ToolMessage(content='Sunny, 15°C', name='get_weather', id='106deb30-c8ad-4bfc-b450-8954f052a952', tool_call_id='3354c9f2-0bcc-4344-8168-37c67d37c5c0'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-12-03T01:19:44.799210344Z', 'done': True, 'done_reason': 'stop', 'total_duration': 522221885, 'load_duration': 138566872, 'prompt_eval_count': 247, 'prompt_eval_duration': 31013511, 'eval_count': 42, 'eval_duration': 317336758, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--19969e4d-5977-4b63-98ed-3dbb87129763-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Tokyo'}, 'id': 'a31d8a1b-5bc1-4a20-82e6-761c53a2cddc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 247, 'output_tokens': 42, 'total_tokens': 289}),\n",
       "  ToolMessage(content='Sunny, 22°C', name='get_weather', id='74c9b4db-4390-454e-9cfa-761f2c808d93', tool_call_id='a31d8a1b-5bc1-4a20-82e6-761c53a2cddc'),\n",
       "  AIMessage(content='Here’s the current weather for each city:\\n\\n| City | Weather | Temperature |\\n|------|---------|-------------|\\n| Seoul | Sunny | 15\\u202f°C |\\n| Tokyo | Sunny | 22\\u202f°C |\\n\\nLet me know if you’d like more details (e.g., humidity, wind speed, forecast for the next few days, or anything else)!', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-12-03T01:19:45.618722487Z', 'done': True, 'done_reason': 'stop', 'total_duration': 804304590, 'load_duration': 143891250, 'prompt_eval_count': 280, 'prompt_eval_duration': 28679924, 'eval_count': 76, 'eval_duration': 578850208, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--cb4e1e73-e5ab-4397-91d9-38ba14b5d7b7-0', usage_metadata={'input_tokens': 280, 'output_tokens': 76, 'total_tokens': 356})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 2: 날씨 정보\n",
    "run_agent(\"What is the weather in Seoul and Tokyo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: Multiply 7 by 8, then add 10 to the result\n",
      "============================================================\n",
      "\n",
      "[AI - Tool Calls]\n",
      "  -> multiply({'a': 7, 'b': 8})\n",
      "\n",
      "[Tool Result] multiply: 56\n",
      "\n",
      "[AI - Final Response]\n",
      "  66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Multiply 7 by 8, then add 10 to the result', additional_kwargs={}, response_metadata={}, id='45a4ef5e-7f3e-4efe-8810-d455cedf0998'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-12-03T01:19:46.603386221Z', 'done': True, 'done_reason': 'stop', 'total_duration': 943910193, 'load_duration': 134085036, 'prompt_eval_count': 218, 'prompt_eval_duration': 50526789, 'eval_count': 94, 'eval_duration': 714373986, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--8b16889f-b8fe-4549-879e-e6b7e5df46db-0', tool_calls=[{'name': 'multiply', 'args': {'a': 7, 'b': 8}, 'id': '72f0cc00-e469-4fe6-a75e-a46fb0c204be', 'type': 'tool_call'}], usage_metadata={'input_tokens': 218, 'output_tokens': 94, 'total_tokens': 312}),\n",
       "  ToolMessage(content='56', name='multiply', id='7cfb69be-d9b7-4c65-9d20-b25b8a566917', tool_call_id='72f0cc00-e469-4fe6-a75e-a46fb0c204be'),\n",
       "  AIMessage(content='66', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b', 'created_at': '2025-12-03T01:19:47.183382598Z', 'done': True, 'done_reason': 'stop', 'total_duration': 561104760, 'load_duration': 134835015, 'prompt_eval_count': 250, 'prompt_eval_duration': 27848996, 'eval_count': 48, 'eval_duration': 364490197, 'logprobs': None, 'model_name': 'gpt-oss:20b', 'model_provider': 'ollama'}, id='lc_run--8b890095-bda6-4bac-ad49-f7bbf00e4ded-0', usage_metadata={'input_tokens': 250, 'output_tokens': 48, 'total_tokens': 298})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 3: 복합 작업\n",
    "run_agent(\"Multiply 7 by 8, then add 10 to the result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 한국어 테스트 (선택사항)\n",
    "\n",
    "일부 로컬 모델은 한국어 지원이 제한적일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 테스트 (모델에 따라 결과가 다를 수 있음)\n",
    "try:\n",
    "    run_agent(\"5와 10을 더해줘\")\n",
    "except Exception as e:\n",
    "    print(f\"한국어 처리 중 오류: {e}\")\n",
    "    print(\"영어로 시도해보세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 스트리밍 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_stream(query: str, agent=react_agent):\n",
    "    \"\"\"에이전트를 스트리밍 모드로 실행합니다.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for event in agent.stream({\"messages\": [(\"human\", query)]}, stream_mode=\"updates\"):\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"\\n[{node_name} node]\")\n",
    "            if \"messages\" in node_output:\n",
    "                for msg in node_output[\"messages\"]:\n",
    "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "                        for tc in msg.tool_calls:\n",
    "                            print(f\"  -> Tool call: {tc['name']}({tc['args']})\")\n",
    "                    elif hasattr(msg, \"content\") and msg.content:\n",
    "                        content = str(msg.content)\n",
    "                        print(f\"  -> {content[:200]}...\" if len(content) > 200 else f\"  -> {content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 테스트\n",
    "run_agent_stream(\"Multiply 5 and 7, then add 10 to the result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 다른 로컬 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent_with_model(model_name: str):\n",
    "    \"\"\"다른 Ollama 모델로 에이전트를 생성합니다.\"\"\"\n",
    "    from langchain_ollama import ChatOllama\n",
    "    from langgraph.prebuilt import create_react_agent\n",
    "    \n",
    "    local_llm = ChatOllama(\n",
    "        model=model_name,\n",
    "        base_url=OLLAMA_URL,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return create_react_agent(local_llm, tools)\n",
    "\n",
    "\n",
    "# 예시: 다른 모델 사용\n",
    "# other_agent = create_agent_with_model(\"gemma3:12b\")\n",
    "# run_agent(\"Add 5 and 3\", agent=other_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 요약\n",
    "\n",
    "### 로컬 모델 사용의 장점\n",
    "- **프라이버시**: 데이터가 외부로 전송되지 않음\n",
    "- **비용**: API 호출 비용 없음\n",
    "- **오프라인**: 인터넷 연결 없이 사용 가능\n",
    "- **커스터마이징**: 모델 파인튜닝 가능\n",
    "\n",
    "### 로컬 모델 사용 시 고려사항\n",
    "- 추론 속도가 상대적으로 느림 (GPU 필요)\n",
    "- 도구 호출 정확도가 상용 모델보다 낮을 수 있음\n",
    "- 한국어 성능이 제한적일 수 있음\n",
    "- 충분한 RAM/VRAM 필요 (최소 8GB 이상 권장)\n",
    "\n",
    "### 권장 모델 (도구 호출 지원)\n",
    "| 모델 | 크기 | 특징 |\n",
    "|------|------|------|\n",
    "| gemma3:4b | 4B | 경량, 빠름, 도구 호출 지원 |\n",
    "| llama3.1 | 8B | 균형 잡힌 성능 |\n",
    "| llama3.2 | 3B | 경량, 빠름 |\n",
    "| mistral | 7B | 우수한 추론 |\n",
    "| qwen2.5 | 7B | 다국어 지원 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}